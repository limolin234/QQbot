import asyncio
import heapq
import inspect
import logging
from time import time
from typing import Any, Callable, Coroutine, List, Optional
import uuid

logger = logging.getLogger(__name__)

# ----------------------------------------------------------------------
# ä¼˜å…ˆçº§é˜Ÿåˆ—æ ¸å¿ƒï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
# ----------------------------------------------------------------------
class Task:
    __slots__ = ('priority', 'data', 'timestamp', 'order', 'task_id', 'future')

    def __init__(self, priority: int, data: Any, future: Optional[asyncio.Future] = None):
        if not 0 <= priority <= 15:
            raise ValueError("priority must be 0-15")
        self.priority = priority
        self.data = data
        self.timestamp = time()
        self.order = 0
        self.task_id = uuid.uuid4().hex[:8]
        self.future = future

    def __lt__(self, other: 'Task') -> bool:
        if self.priority != other.priority:
            return self.priority < other.priority
        return self.order < other.order


class PriorityScheduler:
    def __init__(self, maxsize: int = 0):
        self.maxsize = maxsize
        self._queue: list[Task] = []
        self._counter = 0
        self._lock = asyncio.Lock()
        self._not_empty = asyncio.Condition(self._lock)

    async def put(self, task: Task) -> None:
        async with self._not_empty:
            if self.maxsize > 0 and len(self._queue) >= self.maxsize:
                raise asyncio.QueueFull()
            task.order = self._counter
            self._counter += 1
            heapq.heappush(self._queue, task)
            self._not_empty.notify()

    async def pop(self) -> Task:
        async with self._not_empty:
            while not self._queue:
                await self._not_empty.wait()
            return heapq.heappop(self._queue)

    def qsize(self): return len(self._queue)
    def empty(self): return len(self._queue) == 0
    def full(self): return self.maxsize > 0 and len(self._queue) >= self.maxsize


# ----------------------------------------------------------------------
# å…¨å±€çŠ¶æ€
# ----------------------------------------------------------------------
_scheduler: Optional[PriorityScheduler] = None
_loop: Optional[asyncio.AbstractEventLoop] = None
_worker_tasks: List[asyncio.Task] = []

# LLM å¤„ç†å™¨ï¼ˆé»˜è®¤ä¸º Noneï¼Œå¯åŠ¨åå¿…é¡»æ³¨å†Œï¼‰
_llm_handler: Optional[Callable[[Any], Coroutine[Any, Any, Any]]] = None


# ----------------------------------------------------------------------
# æ³¨å†Œæ¥å£ï¼ˆè£…é¥°å™¨ + å‡½æ•°ï¼‰
# ----------------------------------------------------------------------
def register_llm_handler(func: Optional[Callable[[Any], Coroutine]] = None):
    """
    è£…é¥°å™¨ï¼šæ³¨å†Œ LLM å¤„ç†å™¨ã€‚
    ç”¨æ³•ï¼š
        @register_llm_handler
        async def my_llm_handler(data): ...
    æˆ–ï¼š
        register_llm_handler(my_llm_handler)
    """
    def decorator(f: Callable[[Any], Coroutine]) -> Callable[[Any], Coroutine]:
        global _llm_handler
        _llm_handler = f
        logger.info("LLM å¤„ç†å™¨å·²æ³¨å†Œ: %s", f.__name__)
        return f

    if func is None:
        return decorator
    else:
        return decorator(func)


# ----------------------------------------------------------------------
# Worker æ± ï¼ˆå›ºå®šæ•°é‡ï¼Œä¸²è¡Œæ‰§è¡Œï¼‰
# ----------------------------------------------------------------------
async def _worker(worker_id: int):
    while True:
        task = None
        try:
            task = await _scheduler.pop()
            try:
                result = await _execute_task_payload(task.data)
                if task.future and not task.future.done():
                    task.future.set_result(result)
            except Exception as e:
                logger.exception("Worker-%d å¤„ç†ä»»åŠ¡å¤±è´¥, task_id=%s", worker_id, task.task_id)
                if task.future and not task.future.done():
                    task.future.set_exception(e)

        except asyncio.CancelledError:
            logger.info("Worker-%d å·²å–æ¶ˆ", worker_id)
            break
        except Exception:
            logger.exception("Worker-%d å†…éƒ¨å¼‚å¸¸", worker_id)


async def _execute_task_payload(data: dict[str, Any]) -> Any:
    """
    - æ ¹æ® payload["type"] åˆ†æ”¯ï¼š
    - callableï¼šæ‰§è¡Œå‡½æ•°ï¼ˆsubmit_agent_job(...) èµ°è¿™ä¸ªåˆ†æ”¯ï¼‰ï¼Œæ”¯æŒï¼š
        - run_in_thread=True æ—¶ç”¨ asyncio.to_thread è·‘åŒæ­¥é˜»å¡å‡½æ•°
        - å¦åˆ™ç›´æ¥è°ƒç”¨ï¼›è‹¥è¿”å› awaitable å°± await 
    - llmï¼šèµ°è€çš„ _llm_handlerï¼ˆç»™ agentp_LLM(...) å…¼å®¹ä¿ç•™ï¼‰
    """
    payload_type = str(data.get("type", ""))
    if payload_type == "callable":
        func = data.get("func")
        if not callable(func):
            raise ValueError("callable ä»»åŠ¡ç¼ºå°‘å¯è°ƒç”¨å¯¹è±¡")
        args = data.get("args", ())
        kwargs = data.get("kwargs", {})
        run_in_thread = bool(data.get("run_in_thread", False))
        if run_in_thread:
            return await asyncio.to_thread(func, *args, **kwargs)
        result = func(*args, **kwargs)
        if inspect.isawaitable(result):
            return await result
        return result

    if payload_type == "llm":
        if _llm_handler is None:
            raise RuntimeError("LLM å¤„ç†å™¨æœªæ³¨å†Œï¼Œè¯·å…ˆè°ƒç”¨ register_llm_handler")
        return await _llm_handler(data.get("payload"))

    raise ValueError(f"æœªçŸ¥ä»»åŠ¡ç±»å‹: {payload_type}")


# ----------------------------------------------------------------------
# å¯åŠ¨ / åœæ­¢
# ----------------------------------------------------------------------
async def setup_agent_pool(
    worker_count: int = 5,
    maxsize: int = 100,
    loop: Optional[asyncio.AbstractEventLoop] = None
) -> None:
    """å¯åŠ¨ä»£ç†æ± ï¼ˆåªéœ€è¦ Worker æ•°é‡å’Œé˜Ÿåˆ—å®¹é‡ï¼‰"""
    global _scheduler, _loop, _worker_tasks

    if _scheduler is not None:
        logger.warning("Agent æ± å·²å¯åŠ¨ï¼Œå¿½ç•¥é‡å¤è°ƒç”¨")
        return

    _scheduler = PriorityScheduler(maxsize=maxsize)
    _loop = loop or asyncio.get_running_loop()
    _worker_tasks = [
        asyncio.create_task(_worker(i), name=f"AgentWorker-{i}")
        for i in range(worker_count)
    ]
    logger.info("âœ… Agent æ± å·²å¯åŠ¨ï¼ŒWorker æ•°é‡=%dï¼Œé˜Ÿåˆ—å®¹é‡=%s",
                worker_count, maxsize if maxsize > 0 else "æ— é™åˆ¶")


async def stop_agent_pool() -> None:
    """åœæ­¢ä»£ç†æ± """
    global _worker_tasks, _scheduler, _loop, _llm_handler
    for t in _worker_tasks:
        t.cancel()
    if _worker_tasks:
        await asyncio.gather(*_worker_tasks, return_exceptions=True)
    _worker_tasks.clear()
    _scheduler = None
    _loop = None
    _llm_handler = None
    logger.info("ğŸ›‘ Agent æ± å·²åœæ­¢")


async def _submit_pool_task(
    *,
    payload: dict[str, Any],
    priority: int,
    timeout: float,
) -> Any:
    if _scheduler is None:
        raise RuntimeError("âŒ Agent æ± æœªå¯åŠ¨ï¼Œè¯·å…ˆè°ƒç”¨ setup_agent_pool()")

    loop = _loop or asyncio.get_running_loop()
    future = loop.create_future()
    task = Task(priority=priority, data=payload, future=future)

    try:
        await _scheduler.put(task)
    except asyncio.QueueFull as error:
        raise RuntimeError("Agent æ± é˜Ÿåˆ—å·²æ»¡ï¼Œè¯·æ±‚è¢«æ‹’ç»") from error

    try:
        return await asyncio.wait_for(future, timeout=timeout)
    except asyncio.TimeoutError:
        if not future.done():
            future.cancel()
        raise


async def submit_agent_job(
    func: Callable[..., Any],
    *args: Any,
    priority: int = 7,
    timeout: float = 60.0,
    run_in_thread: Optional[bool] = None,
    **kwargs: Any,
) -> Any:
    """
    æäº¤é€šç”¨ä»»åŠ¡åˆ° Agent æ± è°ƒåº¦æ‰§è¡Œï¼ˆä¸æ”¹å˜ä»»åŠ¡å†…éƒ¨å®ç°æ–¹å¼ï¼‰ã€‚
    
    å®è´¨ä¸Šï¼Œå°±æ˜¯ add_task å‡½æ•°
    """
    run_blocking = not inspect.iscoroutinefunction(func) if run_in_thread is None else bool(run_in_thread)
    payload = {
        "type": "callable",
        "func": func,
        "args": args,
        "kwargs": kwargs,
        "run_in_thread": run_blocking,
    }
    return await _submit_pool_task(payload=payload, priority=priority, timeout=timeout)


# ----------------------------------------------------------------------
# å¯¹å¤–è°ƒç”¨æ¥å£ï¼šawait agentp_LLM(...) ç›´æ¥å¾—åˆ°å›å¤
# ----------------------------------------------------------------------
async def agentp_LLM(
    api_key: str,
    prompt: str,
    api_base: Optional[str] = None,
    model: str = "gpt-3.5-turbo",
    priority: int = 7,
    timeout: float = 30.0,
    **kwargs
) -> str:
    """
    å¼‚æ­¥æäº¤ LLM è¯·æ±‚ï¼Œç­‰å¾…å›å¤ã€‚
    å‚æ•°ä¼šè¢«æ‰“åŒ…æˆå­—å…¸ä¼ é€’ç»™å·²æ³¨å†Œçš„ LLM å¤„ç†å™¨ã€‚
    å¤„ç†å™¨å¿…é¡»è¿”å›å­—ç¬¦ä¸²ï¼ˆæ¨¡å‹å›å¤ï¼‰ã€‚
    """
    request_data = {
        "api_key": api_key,
        "api_base": api_base,
        "prompt": prompt,
        "model": model,
        **kwargs
    }
    result = await _submit_pool_task(
        payload={"type": "llm", "payload": request_data},
        priority=priority,
        timeout=timeout,
    )
    return str(result)


# ----------------------------------------------------------------------
# å…¬å¼€æ¥å£
# ----------------------------------------------------------------------
__all__ = [
    "setup_agent_pool",
    "stop_agent_pool",
    "submit_agent_job",
    "agentp_LLM",
    "register_llm_handler",
]
