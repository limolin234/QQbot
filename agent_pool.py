import asyncio
import heapq
import inspect
import logging
from time import time
from typing import Any, Callable, Coroutine, List, Optional
import uuid

logger = logging.getLogger(__name__)

# ----------------------------------------------------------------------
# ä¼˜å…ˆçº§é˜Ÿåˆ—æ ¸å¿ƒï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
# ----------------------------------------------------------------------
class Task:
    __slots__ = ('priority', 'data', 'timestamp', 'order', 'task_id', 'future')

    def __init__(self, priority: int, data: Any, future: Optional[asyncio.Future] = None):
        if not 0 <= priority <= 15:
            raise ValueError("priority must be 0-15")
        self.priority = priority
        self.data = data
        self.timestamp = time()
        self.order = 0
        self.task_id = uuid.uuid4().hex[:8]
        self.future = future

    def __lt__(self, other: 'Task') -> bool:
        if self.priority != other.priority:
            return self.priority < other.priority
        return self.order < other.order


class PriorityScheduler:
    def __init__(self, maxsize: int = 0):
        self.maxsize = maxsize
        self._queue: list[Task] = []
        self._counter = 0
        self._lock = asyncio.Lock()
        self._not_empty = asyncio.Condition(self._lock)
        self._closed = False

    async def put(self, task: Task) -> None:
        async with self._not_empty:
            if self._closed:
                raise RuntimeError("scheduler is closed")
            if self.maxsize > 0 and len(self._queue) >= self.maxsize:
                raise asyncio.QueueFull()
            task.order = self._counter
            self._counter += 1
            heapq.heappush(self._queue, task)
            self._not_empty.notify()

    async def pop(self) -> Task | None:
        async with self._not_empty:
            while not self._queue:
                if self._closed:
                    return None
                await self._not_empty.wait()
            return heapq.heappop(self._queue)

    async def drain(self) -> list[Task]:
        async with self._not_empty:
            drained: list[Task] = []
            while self._queue:
                drained.append(heapq.heappop(self._queue))
            return drained

    async def close(self) -> None:
        async with self._not_empty:
            self._closed = True
            self._not_empty.notify_all()

    def qsize(self): return len(self._queue)
    def empty(self): return len(self._queue) == 0
    def full(self): return self.maxsize > 0 and len(self._queue) >= self.maxsize


# ----------------------------------------------------------------------
# å…¨å±€çŠ¶æ€
# ----------------------------------------------------------------------
_scheduler: Optional[PriorityScheduler] = None
_loop: Optional[asyncio.AbstractEventLoop] = None
_worker_tasks: List[asyncio.Task] = []
_worker_counter = 0

# LLM å¤„ç†å™¨ï¼ˆé»˜è®¤ä¸º Noneï¼Œå¯åŠ¨åå¿…é¡»æ³¨å†Œï¼‰
_llm_handler: Optional[Callable[[Any], Coroutine[Any, Any, Any]]] = None


# ----------------------------------------------------------------------
# æ³¨å†Œæ¥å£ï¼ˆè£…é¥°å™¨ + å‡½æ•°ï¼‰
# ----------------------------------------------------------------------
def register_llm_handler(func: Optional[Callable[[Any], Coroutine]] = None):
    """
    è£…é¥°å™¨ï¼šæ³¨å†Œ LLM å¤„ç†å™¨ã€‚
    ç”¨æ³•ï¼š
        @register_llm_handler
        async def my_llm_handler(data): ...
    æˆ–ï¼š
        register_llm_handler(my_llm_handler)
    """
    def decorator(f: Callable[[Any], Coroutine]) -> Callable[[Any], Coroutine]:
        global _llm_handler
        _llm_handler = f
        logger.info("LLM å¤„ç†å™¨å·²æ³¨å†Œ: %s", f.__name__)
        return f

    if func is None:
        return decorator
    else:
        return decorator(func)


# ----------------------------------------------------------------------
# Worker æ± ï¼ˆå›ºå®šæ•°é‡ï¼Œä¸²è¡Œæ‰§è¡Œï¼‰
# ----------------------------------------------------------------------
async def _worker(worker_id: int):
    while True:
        task = None
        try:
            task = await _scheduler.pop() # type: ignore[union-attr]
            if task is None:
                break
            if task.data.get("type") == "__retire_worker__":
                logger.info("Worker-%d æ”¶åˆ°ç¼©å®¹ä¿¡å·ï¼Œé€€å‡º", worker_id)
                break
            try:
                result = await _execute_task_payload(task.data)
                if task.future and not task.future.done():
                    task.future.set_result(result)
            except Exception as e:
                logger.exception("Worker-%d å¤„ç†ä»»åŠ¡å¤±è´¥, task_id=%s", worker_id, task.task_id)
                if task.future and not task.future.done():
                    task.future.set_exception(e)

        except asyncio.CancelledError:
            logger.info("Worker-%d å·²å–æ¶ˆ", worker_id)
            break
        except Exception:
            logger.exception("Worker-%d å†…éƒ¨å¼‚å¸¸", worker_id)


def _compact_worker_tasks() -> None:
    global _worker_tasks
    _worker_tasks = [task for task in _worker_tasks if not task.done()]


def _spawn_workers(count: int) -> None:
    global _worker_counter
    for _ in range(count):
        worker_id = _worker_counter
        _worker_counter += 1
        _worker_tasks.append(asyncio.create_task(_worker(worker_id), name=f"AgentWorker-{worker_id}"))


async def _execute_task_payload(data: dict[str, Any]) -> Any:
    """
    - æ ¹æ® payload["type"] åˆ†æ”¯ï¼š
    - callableï¼šæ‰§è¡Œå‡½æ•°ï¼ˆsubmit_agent_job(...) èµ°è¿™ä¸ªåˆ†æ”¯ï¼‰ï¼Œæ”¯æŒï¼š
        - run_in_thread=True æ—¶ç”¨ asyncio.to_thread è·‘åŒæ­¥é˜»å¡å‡½æ•°
        - å¦åˆ™ç›´æ¥è°ƒç”¨ï¼›è‹¥è¿”å› awaitable å°± await 
    - llmï¼šèµ°è€çš„ _llm_handlerï¼ˆç»™ agentp_LLM(...) å…¼å®¹ä¿ç•™ï¼‰
    """
    payload_type = str(data.get("type", ""))
    if payload_type == "callable":
        func = data.get("func")
        if not callable(func):
            raise ValueError("callable ä»»åŠ¡ç¼ºå°‘å¯è°ƒç”¨å¯¹è±¡")
        args = data.get("args", ())
        kwargs = data.get("kwargs", {})
        run_in_thread = bool(data.get("run_in_thread", False))
        if run_in_thread:
            return await asyncio.to_thread(func, *args, **kwargs)
        result = func(*args, **kwargs)
        if inspect.isawaitable(result):
            return await result
        return result

    if payload_type == "llm":
        if _llm_handler is None:
            raise RuntimeError("LLM å¤„ç†å™¨æœªæ³¨å†Œï¼Œè¯·å…ˆè°ƒç”¨ register_llm_handler")
        return await _llm_handler(data.get("payload"))

    raise ValueError(f"æœªçŸ¥ä»»åŠ¡ç±»å‹: {payload_type}")


# ----------------------------------------------------------------------
# å¯åŠ¨ / åœæ­¢
# ----------------------------------------------------------------------
async def setup_agent_pool(
    worker_count: int = 5,
    maxsize: int = 100,
    loop: Optional[asyncio.AbstractEventLoop] = None
) -> None:
    """å¯åŠ¨ä»£ç†æ± ï¼ˆåªéœ€è¦ Worker æ•°é‡å’Œé˜Ÿåˆ—å®¹é‡ï¼‰"""
    global _scheduler, _loop, _worker_tasks, _worker_counter

    if _scheduler is not None:
        logger.warning("Agent æ± å·²å¯åŠ¨ï¼Œå¿½ç•¥é‡å¤è°ƒç”¨")
        return

    _scheduler = PriorityScheduler(maxsize=maxsize)
    _loop = loop or asyncio.get_running_loop()
    _worker_tasks = []
    _worker_counter = 0
    _spawn_workers(worker_count)
    logger.info("âœ… Agent æ± å·²å¯åŠ¨ï¼ŒWorker æ•°é‡=%dï¼Œé˜Ÿåˆ—å®¹é‡=%s",
                worker_count, maxsize if maxsize > 0 else "æ— é™åˆ¶")


async def resize_agent_pool(
    worker_count: int,
    *,
    graceful: bool = True,
    wait_timeout: float = 10.0,
) -> None:
    """åŠ¨æ€è°ƒæ•´ Agent æ±  worker æ•°é‡ã€‚"""
    if worker_count <= 0:
        raise ValueError("worker_count must be > 0")
    if _scheduler is None:
        raise RuntimeError("âŒ Agent æ± æœªå¯åŠ¨ï¼Œè¯·å…ˆè°ƒç”¨ setup_agent_pool()")

    _compact_worker_tasks()
    current_count = len(_worker_tasks)
    if worker_count == current_count:
        return

    if worker_count > current_count:
        _spawn_workers(worker_count - current_count)
        logger.info("Agent æ± æ‰©å®¹å®Œæˆ: %d -> %d", current_count, worker_count)
        return

    to_remove = current_count - worker_count
    if graceful:
        for _ in range(to_remove):
            retire_task = Task(
                priority=0,
                data={"type": "__retire_worker__"},
                future=None,
            )
            await _scheduler.put(retire_task)

        end_time = asyncio.get_running_loop().time() + max(wait_timeout, 0.1)
        while True:
            _compact_worker_tasks()
            if len(_worker_tasks) <= worker_count:
                break
            if asyncio.get_running_loop().time() >= end_time:
                logger.warning("Agent æ± ç¼©å®¹ç­‰å¾…è¶…æ—¶ï¼Œç»§ç»­æ‰§è¡Œå½“å‰çŠ¶æ€")
                break
            await asyncio.sleep(0.05)
        logger.info("Agent æ± å¹³æ»‘ç¼©å®¹å®Œæˆ: %d -> %d", current_count, len(_worker_tasks))
        return

    cancelled_workers = _worker_tasks[-to_remove:]
    for worker in cancelled_workers:
        worker.cancel()
    await asyncio.gather(*cancelled_workers, return_exceptions=True)
    _compact_worker_tasks()
    logger.info("Agent æ± å¼ºåˆ¶ç¼©å®¹å®Œæˆ: %d -> %d", current_count, len(_worker_tasks))


async def stop_agent_pool(
    *,
    wait_for_pending: bool = True,
    drop_pending: bool = False,
) -> list[dict[str, Any]]:
    """åœæ­¢ä»£ç†æ± å¹¶æŒ‰éœ€è¿”å›æœªæ‰§è¡Œä»»åŠ¡ä¿¡æ¯ã€‚"""
    global _worker_tasks, _scheduler, _loop, _llm_handler
    if _scheduler is None:
        return []

    drained_tasks: list[Task] = []
    if drop_pending or not wait_for_pending:
        drained_tasks = await _scheduler.drain()
        for task in drained_tasks:
            if task.future and not task.future.done():
                task.future.cancel()

    await _scheduler.close()

    if not wait_for_pending:
        for task in _worker_tasks:
            task.cancel()

    if _worker_tasks:
        await asyncio.gather(*_worker_tasks, return_exceptions=True)
    _worker_tasks.clear()
    _scheduler = None
    _loop = None
    _llm_handler = None
    pending_info = [
        {
            "priority": task.priority,
            "task_type": str(task.data.get("type", "")),
            "task_id": task.task_id,
        }
        for task in drained_tasks
    ]
    logger.info("ğŸ›‘ Agent æ± å·²åœæ­¢ï¼Œæœªæ‰§è¡Œä»»åŠ¡=%d", len(pending_info))
    return pending_info


async def _submit_pool_task(
    *,
    payload: dict[str, Any],
    priority: int,
    timeout: float,
) -> Any:
    if _scheduler is None:
        raise RuntimeError("âŒ Agent æ± æœªå¯åŠ¨ï¼Œè¯·å…ˆè°ƒç”¨ setup_agent_pool()")

    loop = _loop or asyncio.get_running_loop()
    future = loop.create_future()
    task = Task(priority=priority, data=payload, future=future)

    try:
        await _scheduler.put(task)
    except asyncio.QueueFull as error:
        raise RuntimeError("Agent æ± é˜Ÿåˆ—å·²æ»¡ï¼Œè¯·æ±‚è¢«æ‹’ç»") from error
    except RuntimeError as error:
        raise RuntimeError("Agent æ± å·²åœæ­¢ï¼Œæ‹’ç»æ¥æ”¶æ–°ä»»åŠ¡") from error

    try:
        return await asyncio.wait_for(future, timeout=timeout)
    except asyncio.TimeoutError:
        if not future.done():
            future.cancel()
        raise


async def submit_agent_job(
    func: Callable[..., Any],
    *args: Any,
    priority: int = 7,
    timeout: float = 60.0,
    run_in_thread: Optional[bool] = None,
    **kwargs: Any,
) -> Any:
    """
    æäº¤é€šç”¨ä»»åŠ¡åˆ° Agent æ± è°ƒåº¦æ‰§è¡Œï¼ˆä¸æ”¹å˜ä»»åŠ¡å†…éƒ¨å®ç°æ–¹å¼ï¼‰ã€‚
    
    å®è´¨ä¸Šï¼Œå°±æ˜¯ add_task å‡½æ•°
    """
    run_blocking = not inspect.iscoroutinefunction(func) if run_in_thread is None else bool(run_in_thread)
    payload = {
        "type": "callable",
        "func": func,
        "args": args,
        "kwargs": kwargs,
        "run_in_thread": run_blocking,
    }
    return await _submit_pool_task(payload=payload, priority=priority, timeout=timeout)


# ----------------------------------------------------------------------
# å¯¹å¤–è°ƒç”¨æ¥å£ï¼šawait agentp_LLM(...) ç›´æ¥å¾—åˆ°å›å¤
# ----------------------------------------------------------------------
async def agentp_LLM(
    api_key: str,
    prompt: str,
    api_base: Optional[str] = None,
    model: str = "gpt-3.5-turbo",
    priority: int = 7,
    timeout: float = 30.0,
    **kwargs
) -> str:
    """
    å¼‚æ­¥æäº¤ LLM è¯·æ±‚ï¼Œç­‰å¾…å›å¤ã€‚
    å‚æ•°ä¼šè¢«æ‰“åŒ…æˆå­—å…¸ä¼ é€’ç»™å·²æ³¨å†Œçš„ LLM å¤„ç†å™¨ã€‚
    å¤„ç†å™¨å¿…é¡»è¿”å›å­—ç¬¦ä¸²ï¼ˆæ¨¡å‹å›å¤ï¼‰ã€‚
    """
    request_data = {
        "api_key": api_key,
        "api_base": api_base,
        "prompt": prompt,
        "model": model,
        **kwargs
    }
    result = await _submit_pool_task(
        payload={"type": "llm", "payload": request_data},
        priority=priority,
        timeout=timeout,
    )
    return str(result)


# ----------------------------------------------------------------------
# å…¬å¼€æ¥å£
# ----------------------------------------------------------------------
__all__ = [
    "setup_agent_pool",
    "resize_agent_pool",
    "stop_agent_pool",
    "submit_agent_job",
    "agentp_LLM",
    "register_llm_handler",
]
